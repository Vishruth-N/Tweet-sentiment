{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-Jn879kE1My",
        "outputId": "c52b118e-1490-4bcb-983f-81b1b0bbfd35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.pipeline import Pipeline\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "import re\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_tweet(text):\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "    text = re.sub(r'\\@\\w+|\\#', '', text)\n",
        "    text = text.lower()\n",
        "    text_tokens = word_tokenize(text)\n",
        "    filtered_words = [word for word in text_tokens if word not in stopwords.words('english')]\n",
        "    return ' '.join(filtered_words)"
      ],
      "metadata": {
        "id": "eWXEOPAIE5mZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(file_path):\n",
        "    data = pd.read_csv(file_path)\n",
        "    data['text'] = data['text'].apply(preprocess_tweet)\n",
        "    return data"
      ],
      "metadata": {
        "id": "ODGgXUC9GCch"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = 'dataset.csv'\n",
        "data = load_data(file_path)"
      ],
      "metadata": {
        "id": "mY_nGGGUGHuv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data['text'], data['sentiment'], test_size=0.2, random_state=42)\n",
        "\n",
        "text_clf = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('clf', MultinomialNB()),\n",
        "])"
      ],
      "metadata": {
        "id": "a4Za-ML-GNXW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_clf.fit(X_train, y_train)\n",
        "predictions = text_clf.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, predictions));"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHG4UMbrGSXB",
        "outputId": "64a8ddd6-0684-4def-d800-ad22c07804f8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "            AOC       0.61      0.79      0.68       727\n",
            "    BarackObama       0.00      0.00      0.00       148\n",
            "      Cristiano       1.00      0.11      0.20       100\n",
            "  GretaThunberg       1.00      0.54      0.70       337\n",
            "HIDEO_KOJIMA_EN       0.88      0.79      0.83       732\n",
            "         Malala       0.00      0.00      0.00        46\n",
            "          Oprah       0.00      0.00      0.00       102\n",
            "   TheEllenShow       0.63      0.80      0.70       994\n",
            "       elonmusk       1.00      0.20      0.33       359\n",
            "        garyvee       0.52      0.83      0.64      1311\n",
            "     jk_rowling       0.97      0.26      0.41       290\n",
            "       joerogan       0.94      0.68      0.79       661\n",
            "jordanbpeterson       0.78      0.72      0.75       926\n",
            "       ladygaga       1.00      0.11      0.21       157\n",
            "   narendramodi       0.69      0.99      0.81      1355\n",
            "      neiltyson       1.00      0.10      0.18       218\n",
            " richardbranson       0.85      0.93      0.89       753\n",
            "  taylorswift13       0.00      0.00      0.00        67\n",
            "       tferriss       0.90      0.63      0.74       608\n",
            "\n",
            "       accuracy                           0.70      9891\n",
            "      macro avg       0.67      0.45      0.47      9891\n",
            "   weighted avg       0.74      0.70      0.67      9891\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "report = classification_report(y_test, predictions, output_dict=True)\n",
        "cm = confusion_matrix(y_test, predictions)\n",
        "\n",
        "def latex_output(report, cm):\n",
        "    report_latex = '\\\\begin{tabular}{lrrr}\\n'\n",
        "    report_latex += '\\\\hline\\n'\n",
        "    report_latex += '\\\\textbf{Class} & \\\\textbf{Precision} & \\\\textbf{Recall} & \\\\textbf{F1-Score} \\\\\\\\\\n'\n",
        "    report_latex += '\\\\hline\\n'\n",
        "\n",
        "    for label, metrics in report.items():\n",
        "        if label != 'accuracy':\n",
        "            label = label.replace('_', ' ')  # Replace underscores with spaces\n",
        "            report_latex += f'{label} & {metrics[\"precision\"]:.2f} & {metrics[\"recall\"]:.2f} & {metrics[\"f1-score\"]:.2f} \\\\\\\\\\n'\n",
        "\n",
        "    report_latex += '\\\\hline\\n'\n",
        "    report_latex += '\\\\end{tabular}\\n'\n",
        "\n",
        "\n",
        "    cm_latex = '\\\\begin{bmatrix}\\n'\n",
        "\n",
        "    for row in cm:\n",
        "        row_str = ' & '.join(str(x) for x in row)\n",
        "        cm_latex += f'{row_str} \\\\\\\\\\n'\n",
        "\n",
        "    cm_latex += '\\\\end{bmatrix}'\n",
        "\n",
        "    return report_latex, cm_latex\n"
      ],
      "metadata": {
        "id": "gY3-jrufL89P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report_latex, cm_latex = latex_output(report, cm)\n",
        "\n",
        "from IPython.display import display, Math\n",
        "display(Math(f'\\\\text{{Confusion Matrix}}\\\\\\\\\\n{cm_latex}'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "KAV-RzMcMF_-",
        "outputId": "67cc10d8-612b-47aa-9b16-b81d27ec281d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Math object>"
            ],
            "text/latex": "$\\displaystyle \\text{Confusion Matrix}\\\\\n\\begin{bmatrix}\n573 & 0 & 0 & 0 & 4 & 0 & 0 & 29 & 0 & 50 & 0 & 2 & 9 & 0 & 55 & 0 & 3 & 0 & 2 \\\\\n76 & 0 & 0 & 0 & 0 & 0 & 0 & 24 & 0 & 13 & 0 & 1 & 5 & 0 & 21 & 0 & 8 & 0 & 0 \\\\\n4 & 0 & 11 & 0 & 2 & 0 & 0 & 13 & 0 & 38 & 0 & 0 & 2 & 0 & 28 & 0 & 2 & 0 & 0 \\\\\n45 & 0 & 0 & 181 & 3 & 0 & 0 & 9 & 0 & 26 & 1 & 1 & 21 & 0 & 26 & 0 & 22 & 0 & 2 \\\\\n11 & 0 & 0 & 0 & 576 & 0 & 0 & 50 & 0 & 58 & 0 & 1 & 6 & 0 & 21 & 0 & 6 & 0 & 3 \\\\\n8 & 0 & 0 & 0 & 0 & 0 & 0 & 4 & 0 & 8 & 0 & 0 & 2 & 0 & 20 & 0 & 3 & 0 & 1 \\\\\n6 & 0 & 0 & 0 & 1 & 0 & 0 & 43 & 0 & 42 & 0 & 0 & 0 & 0 & 10 & 0 & 0 & 0 & 0 \\\\\n19 & 0 & 0 & 0 & 7 & 0 & 0 & 800 & 0 & 102 & 0 & 1 & 6 & 0 & 47 & 0 & 7 & 0 & 5 \\\\\n26 & 0 & 0 & 0 & 15 & 0 & 0 & 41 & 72 & 105 & 0 & 2 & 23 & 0 & 55 & 0 & 16 & 0 & 4 \\\\\n13 & 0 & 0 & 0 & 6 & 0 & 0 & 49 & 0 & 1091 & 0 & 8 & 13 & 0 & 119 & 0 & 7 & 0 & 5 \\\\\n33 & 0 & 0 & 0 & 6 & 0 & 0 & 50 & 0 & 56 & 75 & 0 & 36 & 0 & 29 & 0 & 5 & 0 & 0 \\\\\n10 & 0 & 0 & 0 & 1 & 0 & 0 & 17 & 0 & 143 & 0 & 452 & 20 & 0 & 8 & 0 & 5 & 0 & 5 \\\\\n50 & 0 & 0 & 0 & 4 & 0 & 0 & 29 & 0 & 95 & 0 & 5 & 666 & 0 & 60 & 0 & 10 & 0 & 7 \\\\\n13 & 0 & 0 & 0 & 5 & 0 & 0 & 36 & 0 & 48 & 0 & 3 & 2 & 18 & 27 & 0 & 2 & 0 & 3 \\\\\n4 & 0 & 0 & 0 & 2 & 0 & 0 & 5 & 0 & 7 & 0 & 1 & 0 & 0 & 1336 & 0 & 0 & 0 & 0 \\\\\n25 & 0 & 0 & 0 & 13 & 0 & 0 & 27 & 0 & 67 & 0 & 3 & 22 & 0 & 22 & 22 & 14 & 0 & 3 \\\\\n9 & 0 & 0 & 0 & 1 & 0 & 0 & 4 & 0 & 18 & 0 & 0 & 0 & 0 & 20 & 0 & 701 & 0 & 0 \\\\\n2 & 0 & 0 & 0 & 2 & 0 & 0 & 15 & 0 & 33 & 0 & 0 & 2 & 0 & 6 & 0 & 3 & 0 & 4 \\\\\n20 & 0 & 0 & 0 & 10 & 0 & 0 & 33 & 0 & 105 & 1 & 0 & 19 & 0 & 28 & 0 & 9 & 0 & 383 \\\\\n\\end{bmatrix}$"
          },
          "metadata": {}
        }
      ]
    }
  ]
}